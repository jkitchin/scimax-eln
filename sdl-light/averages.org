#+title: Reproducibility, significant differences and interactions in the SDL-Light
#+date: [2024-07-04 Thu]



#+BEGIN_SRC jupyter-python
import numpy as np
import matplotlib.pyplot as plt
from self_driving_lab_demo import (get_paho_client, mqtt_observe_sensor_data)

PICO_ID = 'test'
client = get_paho_client(f"sdl-demo/picow/{PICO_ID}/as7341/")

from pycse.hashcache import HashCache

@HashCache
def get_results(R, G, B, label=None):
    return mqtt_observe_sensor_data(R, G, B, pico_id=PICO_ID, client=client)

def measure(R, G, B, label=None):
    results = get_results(R, G, B, label)
    return results['ch620'], results['ch510'], results['ch470']
#+END_SRC

#+RESULTS:


* Reproducibility

We have to evaluate how reproducible a measurement is, and whether it is impacted by how we measure it. 

** A baseline

We establish a base line here by making the same measurement 50 times. We have to assume that what we measure here will be similar at other values.

#+BEGIN_SRC jupyter-python  :async yes
from tqdm import tqdm
base = []
for i in tqdm(range(50)):
    base += [measure(50, 50, 50, f'jul-4-base-{i}')]
#+END_SRC

#+RESULTS:
: 100% 50/50 [00:00<00:00, 130.52it/s]

#+BEGIN_SRC jupyter-python
import numpy as np

np.mean(base, axis=0), np.std(base, axis=0)
#+END_SRC

#+RESULTS:
| array | ((11957.18 8297 12327.6)) | array | ((10.35121249 6.91375441 8.67179336)) |

We should check if there are any temporal trends, e.g. a systematic change in the order we ran these. This could happen for a variety of reasons, e.g. something heats up and changes over time, something degrades over time, etc.

#+BEGIN_SRC jupyter-python
plt.plot(base - np.mean(base, axis=0))
plt.xlabel('sequence')
plt.ylabel('RGB');
#+END_SRC

#+RESULTS:
[[./.ob-jupyter/755f60f999b09f885b2a2e8a4408c49c7cca604f.png]]

It actually does appear there is a shift over time here, but it is not large.

#+BEGIN_SRC jupyter-python
fig, axs = plt.subplots(1, 3)
C = 'rgb'
for i, c in enumerate(C):
    axs[i].hist(base[:, i], color=C[i])
#+END_SRC

#+RESULTS:
[[./.ob-jupyter/a3583a84b92391f7370ebd12a3ebc934a65de31c.png]]

** Perturbations on R, G and B

#+BEGIN_SRC jupyter-python
R = []
for i in tqdm(range(50)):
    R += [measure(51, 50, 50, f'jul-4-R-{i}')]

G = []
for i in tqdm(range(50)):
    G += [measure(50, 51, 50, f'jul-4-G-{i}')]

B = []
for i in tqdm(range(50)):
    B += [measure(50, 50, 51, f'jul-4-B-{i}')]        

base = np.array(base)
R = np.array(R)
G = np.array(G)
B = np.array(B)
#+END_SRC

#+RESULTS:
: 100% 50/50 [00:00<00:00, 149.70it/s]
: 100% 50/50 [00:00<00:00, 250.64it/s]
: 100% 50/50 [00:00<00:00, 116.88it/s]


#+BEGIN_SRC jupyter-python
plt.plot(R - np.mean(R, axis=0), c='r');
plt.plot(G - np.mean(G, axis=0), c='b');
plt.plot(B - np.mean(B, axis=0), c='g');
#+END_SRC

#+RESULTS:
[[./.ob-jupyter/f85beaa9434ae830126d7b271b5d986ee31eadba.png]]

It is not obvious there is any drift here.

*** R channel analysis

#+BEGIN_SRC jupyter-python
import matplotlib.pyplot as plt
fig, (ax1, ax2, ax3) = plt.subplots(1, 3)

ax1.hist(base[:, 0], color='k', alpha=0.5);
ax1.hist(R[:, 0], color='r', alpha=0.5);

ax2.hist(base[:, 1], color='k', alpha=0.5);
ax2.hist(R[:, 1], color='g', alpha=0.5);

ax3.hist(base[:, 2], color='k', alpha=0.5);
ax3.hist(R[:, 2], color='b', alpha=0.5);
#+END_SRC

#+RESULTS:
[[./.ob-jupyter/9b40ad05466a617fc73c5b7a5abc561496d86034.png]]


#+BEGIN_SRC jupyter-python
np.mean(R, axis=0) - np.mean(base, axis=0)
#+END_SRC

#+RESULTS:
: array([306.36,   0.82,   2.4 ])

Z-scores

#+BEGIN_SRC jupyter-python
np.abs(np.mean(R, axis=0) - np.mean(base, axis=0)) / np.std(base, axis=0)
#+END_SRC

#+RESULTS:
: array([29.5965328 ,  0.11860416,  0.27675936])

For these measurements the difference in the red channel is unambigously real, and we cannot say the difference in the other channels is meaningful.

*** G channel analysis

#+BEGIN_SRC jupyter-python
fig, (ax1, ax2, ax3) = plt.subplots(1, 3)

ax1.hist(base[:, 0], color='k', alpha=0.5);
ax1.hist(G[:, 0], color='r', alpha=0.5);

ax2.hist(base[:, 1], color='k', alpha=0.5);
ax2.hist(G[:, 1], color='g', alpha=0.5);

ax3.hist(base[:, 2], color='k', alpha=0.5);
ax3.hist(G[:, 2], color='b', alpha=0.5);
#+END_SRC

#+RESULTS:
[[./.ob-jupyter/e8793acc717247acaa2fa072203ccf33f626165d.png]]

#+BEGIN_SRC jupyter-python
(np.mean(G, axis=0) - np.mean(base, axis=0)).round(1)
#+END_SRC

#+RESULTS:
: array([  0. , 198.1,  81.9])

Z scores
#+BEGIN_SRC jupyter-python
(np.abs(np.mean(G, axis=0) - np.mean(base, axis=0)) / np.std(base, axis=0)).round(1)
#+END_SRC

#+RESULTS:
: array([ 0. , 28.6,  9.4])

Here there is a meaningful difference in G and B, and no difference in R.

*** B channel analysis

#+BEGIN_SRC jupyter-python
fig, (ax1, ax2, ax3) = plt.subplots(1, 3)

ax1.hist(base[:, 0], color='k', alpha=0.5);
ax1.hist(B[:, 0], color='r', alpha=0.5);

ax2.hist(base[:, 1], color='k', alpha=0.5);
ax2.hist(B[:, 1], color='g', alpha=0.5);

ax3.hist(base[:, 2], color='k', alpha=0.5);
ax3.hist(B[:, 2], color='b', alpha=0.5);
#+END_SRC

#+RESULTS:
[[./.ob-jupyter/6d5d2902633e55bbad4cdeece5205aaf07c2e0d6.png]]

#+BEGIN_SRC jupyter-python
(np.mean(B, axis=0) - np.mean(base, axis=0)).round(1)
#+END_SRC

#+RESULTS:
: array([-23.8,  -4.4, 202.4])

Z-scores

#+BEGIN_SRC jupyter-python
np.abs(np.mean(B, axis=0) - np.mean(base, axis=0)) / np.std(base, axis=0)
#+END_SRC

#+RESULTS:
: array([ 2.29924755,  0.63062697, 23.34465222])

Curiously,  there is a significant difference in R here, but not in B.

** How linear is it?
:PROPERTIES:
:ID:       1EDE044E-5371-43EC-9AE0-89373DB350EF
:END:

Here we check the output of the measurements over a range of settings for each color channel. We expect that the main effect should be on the channel closest in color, and the other channels should be flat. If they are not flat, it means there is some interaction or cross-talk between the channels.

#+BEGIN_SRC jupyter-python
setting = np.arange(0, 100, 5)

R, G, B = [], [], []
for i in setting:
    R += [measure(i, 0, 0)]
    G += [measure(0, i, 0)]
    B += [measure(0, 0, i)]
    
R = np.array(R)
G = np.array(G)
B = np.array(B)

fig, axs = plt.subplots(1, 3)
p = axs[0].plot(setting, R, '.-')
axs[0].set_title('Vary R')
for c, line in enumerate(p):
    line.set_color('rgb'[c])

p = axs[1].plot(setting, G, '.-')
axs[1].set_title('Vary G')
for c, line in enumerate(p):
    line.set_color('rgb'[c])

p = axs[2].plot(setting, B, '.-')
axs[2].set_title('Vary B')
for c, line in enumerate(p):
    line.set_color('rgb'[c])
    
plt.tight_layout();
#+END_SRC

#+RESULTS:
[[./.ob-jupyter/fe7faa381c7dde9e8fda97153f71b13ac29cb369.png]]


By inspection we can see that there is certainly cross-talk, or some interaction between the channels. That probably means the R, G, B LED is not "pure", but outputs a range of wavelengths that these channels are detecting. The G channel of the LED for example, obviously outputs a blue light component, and the B channel of the LED appears to have a small amount of red and green light in it.

It is also evident the output is nonlinear at low settings.

** What states are actually accessible

We are going to randomly sample three states on each channel. It is important to set a random seed here for reproducibility. To retrieve these results from the cache, you have to use the same seed, otherwise you will get new random numbers which will trigger new experiments.

#+BEGIN_SRC jupyter-python
np.random.seed(42)
states = []
for i in tqdm(range(150)):
    states += [measure(np.random.choice([43, 44, 45]),
                       np.random.choice([58, 59, 60]),
                       np.random.choice([34, 35, 36]),
                       f'state-{i}')]

states = np.array(states)    

plt.scatter(*states[:, 0:2].T, c=states[:, 2], alpha=0.2)
plt.xlabel('R output')
plt.ylabel('G output')
plt.colorbar();
#+END_SRC

#+RESULTS:
:RESULTS:
: 100% 150/150 [00:00<00:00, 151.26it/s]
[[./.ob-jupyter/816ff2c833d8da9225016b4226134b67850e579f.png]]
:END:

This makes it more clear we cannot access all output state space because the input space is discretized. There are some unusual outliers too.

